{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Danyal', 'David', 'Joe', 'May', 'Obama', 'Srivas', 'Unknown']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25632/2662376703.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mencodedKnownList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencodeImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknownImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Encoding Complete'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25632/2662376703.py\u001b[0m in \u001b[0;36mencodeImages\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mencodeImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mknownImages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mcurrentEncode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mencodedList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrentEncode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mencodedList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/Danyal/AppData/Local/Programs/Python/Python39/Lib/site-packages')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import pygame\n",
    "import datetime\n",
    "import time \n",
    "\n",
    "# Declaring Variables \n",
    "path = 'KnownImages'\n",
    "knownImages = []\n",
    "studentNames = []\n",
    "encodedList = []\n",
    "myList = os.listdir(path)\n",
    "\n",
    "pTime = 0\n",
    "name = \"UNKOWN\"\n",
    "currentFrameImg = face_recognition.load_image_file(\"KnownImages/Unknown.jpg\")\n",
    "currentLocImg = face_recognition.face_locations(currentFrameImg)\n",
    "currentEncodeImg = face_recognition.face_encodings(currentFrameImg)[0]\n",
    "\n",
    "# Importing all Images and appending filename to list\n",
    "for i in myList:\n",
    "    current = cv2.imread(f'{path}/{i}')\n",
    "    knownImages.append(current)\n",
    "    studentNames.append(os.path.splitext(i)[0])\n",
    "print(studentNames)\n",
    "\n",
    "\n",
    "# Encoding all the Known Images\n",
    "def encodeImages(images):\n",
    "    for image in knownImages:\n",
    "        currentEncode = face_recognition.face_encodings(image)[0]\n",
    "        encodedList.append(currentEncode)\n",
    "    return encodedList\n",
    "\n",
    "# Marking students attendance \n",
    "def attendanceMark(name):\n",
    "    with open('Attendance.csv','r+') as attFile:\n",
    "        AttendanceList = attFile.readlines()\n",
    "        nameList = []\n",
    "        for line in AttendanceList:\n",
    "            pointer = line.split(',')\n",
    "            nameList.append(pointer[0])\n",
    "        if name not in nameList:\n",
    "            currentTime = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "            attFile.writelines(f'\\n{name},{currentTime}')\n",
    "           \n",
    "        \n",
    "encodedKnownList = encodeImages(knownImages)\n",
    "print('Encoding Complete')\n",
    "\n",
    "# Calling the sound which indicates a match\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.set_num_channels(8)\n",
    "voice = pygame.mixer.Channel(2)\n",
    "correctSound = pygame.mixer.Sound(\"Correct.mp3\")\n",
    "\n",
    "lastTime = datetime.datetime.now()\n",
    "currentTime = datetime.datetime.now()\n",
    "\n",
    "# Get user supplied values\n",
    "cascPath = sys.argv[1]\n",
    "# Create the haar cascade\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "# Setting video source to the default webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()  \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the video\n",
    "    faces = (faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1, \n",
    "        minNeighbors=5,\n",
    "        minSize=(50, 50),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    )\n",
    "    \n",
    "    \"\"\" For more accurate name tagging can use the current frame but FPS is too low \"\"\"\n",
    "    #currentFrameLoc = face_recognition.face_locations(frame)\n",
    "    #currentFrameEnc = face_recognition.face_encodings(frame, currentFrameLoc)\n",
    "    \n",
    "    # Calculating FPS\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    pTime = cTime \n",
    "    cv2.putText(frame,f'FPS: {int(fps)}',(20, 50),cv2.FONT_HERSHEY_PLAIN,2,(255,255,255), 2)\n",
    "\n",
    "    # Plays Sound, if there is a face and previous sound isnt playing  \n",
    "    if len(faces) > 0:\n",
    "        if voice.get_busy() == False:\n",
    "            if(currentTime - lastTime).seconds > 1.5:\n",
    "                lastTime = datetime.datetime.now()\n",
    "                voice.play(correctSound)\n",
    "              \n",
    "            \n",
    "    # Comparing face encodings, Lower Distance = face is more similar\n",
    "    for i,y in zip(currentEncodeImg, currentLocImg):\n",
    "        results = face_recognition.compare_faces(encodedKnownList, i)\n",
    "        distance = face_recognition.face_distance(encodedKnownList, i)\n",
    "        #print(distance)\n",
    "        resultsIndex = np.argmin(distance)\n",
    "        if results[resultsIndex]:\n",
    "            #print(distance[np.argmin(distance)])\n",
    "            if distance[np.argmin(distance)] > 0.42:\n",
    "                name = 'UNKNOWN'\n",
    "            else:\n",
    "                name = studentNames[resultsIndex].upper()\n",
    "                attendanceMark(name)\n",
    "                \n",
    "    # Draw a rectangle around the faces, Save and encode Frame \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.rectangle(frame, (x-2, y+h+40), (x+w, y+h), (0, 255, 0), cv2.FILLED)\n",
    "        cv2.putText(frame,name,(x+12, y+h+28),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255), 2)\n",
    "        filename = datetime.datetime.now().strftime(\"%d_%m_%Y-%I_%M_%S_%p\")\n",
    "        cv2.imwrite('UnknownImages/' + str(filename) +'.jpg',frame) \n",
    "        currentFrameImg = face_recognition.load_image_file('UnknownImages/' + str(filename) +'.jpg')\n",
    "        currentEncodeImg = face_recognition.face_encodings(currentFrameImg)\n",
    "        currentTime = datetime.datetime.now()\n",
    "        \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    # Exists if q key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "        \n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Need to boost FPS by changing classifier to improve speed\n",
    "#Need to retake image with srivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
